{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1eda8f2",
   "metadata": {},
   "source": [
    "# Agent Behavior Visualization\n",
    "\n",
    "This notebook implements visualization tools for analyzing agent behaviors in a SAT solver environment. We'll create visualizations to track agent movements, interactions, and other behaviors over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2caa3",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8204f6b2",
   "metadata": {},
   "source": [
    "## Load the Agent Behavior Data\n",
    "\n",
    "In this section, we'll load and prepare the agent behavior data for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read agent data from CSV files\n",
    "def load_agent_data(file_path):\n",
    "    \"\"\"Load agent behavior data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file containing agent data\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Data frame containing agent behavior data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(\n",
    "            f\"Data loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns\"\n",
    "        )\n",
    "        print(f\"Columns: {data.columns.tolist()}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage (replace with your actual data path)\n",
    "# For demonstration, we'll create simulated data if a file is not specified\n",
    "file_path = \"agent_behavior_data.csv\"  # Update this path as needed\n",
    "\n",
    "\n",
    "# Create synthetic data if needed for demonstration\n",
    "def create_sample_data(num_agents=5, timestamps=100):\n",
    "    \"\"\"Generate synthetic agent behavior data for demonstration.\"\"\"\n",
    "    agent_ids = range(1, num_agents + 1)\n",
    "    data = []\n",
    "\n",
    "    for t in range(timestamps):\n",
    "        for agent_id in agent_ids:\n",
    "            # Simulate random walk with some drift\n",
    "            x = np.sin(t / 10) * 5 + np.random.normal(0, 1) + agent_id\n",
    "            y = np.cos(t / 10) * 5 + np.random.normal(0, 1) + agent_id\n",
    "\n",
    "            # Add some variables representing agent state\n",
    "            state = np.random.choice([\"searching\", \"exploiting\", \"backtracking\"])\n",
    "            energy = max(0, 100 - t / 2 + np.random.normal(0, 5))\n",
    "\n",
    "            data.append(\n",
    "                {\n",
    "                    \"timestamp\": t,\n",
    "                    \"agent_id\": agent_id,\n",
    "                    \"x_position\": x,\n",
    "                    \"y_position\": y,\n",
    "                    \"state\": state,\n",
    "                    \"energy\": energy,\n",
    "                    \"success_rate\": np.random.uniform(0.2, 0.8),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Try to load the data, or create sample data if the file doesn't exist\n",
    "try:\n",
    "    agent_data = load_agent_data(file_path)\n",
    "    if agent_data is None:\n",
    "        print(\"Using synthetic data for demonstration\")\n",
    "        agent_data = create_sample_data()\n",
    "except:\n",
    "    print(\"Using synthetic data for demonstration\")\n",
    "    agent_data = create_sample_data()\n",
    "\n",
    "# Display the first few rows of the data\n",
    "agent_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a157f",
   "metadata": {},
   "source": [
    "## Visualize Agent Movements\n",
    "\n",
    "Now we'll create visualizations to track agent movements over time. This includes:\n",
    "1. Static plots of agent positions\n",
    "2. Trajectory plots showing agent movements over time\n",
    "3. Animated visualizations of agent movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create static plot of agent positions at a specific time\n",
    "def plot_agent_positions(data, timestamp=None):\n",
    "    \"\"\"Plot agent positions at a specific timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "    timestamp (int): Specific timestamp to visualize (if None, use the last timestamp)\n",
    "    \"\"\"\n",
    "    if timestamp is None:\n",
    "        timestamp = data[\"timestamp\"].max()\n",
    "\n",
    "    # Filter data for the specific timestamp\n",
    "    time_data = data[data[\"timestamp\"] == timestamp]\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create a scatter plot of agent positions\n",
    "    scatter = plt.scatter(\n",
    "        time_data[\"x_position\"],\n",
    "        time_data[\"y_position\"],\n",
    "        c=time_data[\"agent_id\"],\n",
    "        s=100,\n",
    "        cmap=\"viridis\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "    plt.title(f\"Agent Positions at Timestamp {timestamp}\")\n",
    "\n",
    "    # Add a legend to identify agents\n",
    "    plt.colorbar(scatter, label=\"Agent ID\")\n",
    "\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to plot agent trajectories over time\n",
    "def plot_agent_trajectories(data, agent_ids=None):\n",
    "    \"\"\"Plot the trajectories of agents over time.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "    agent_ids (list): List of agent IDs to include (None = all agents)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    if agent_ids is None:\n",
    "        agent_ids = sorted(data[\"agent_id\"].unique())\n",
    "\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(agent_ids)))\n",
    "\n",
    "    for i, agent_id in enumerate(agent_ids):\n",
    "        agent_data = data[data[\"agent_id\"] == agent_id]\n",
    "        plt.plot(\n",
    "            agent_data[\"x_position\"],\n",
    "            agent_data[\"y_position\"],\n",
    "            \"-o\",\n",
    "            linewidth=1.5,\n",
    "            markersize=4,\n",
    "            alpha=0.7,\n",
    "            color=colors[i],\n",
    "            label=f\"Agent {agent_id}\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "    plt.title(\"Agent Trajectories Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create an interactive animation of agent movements using Plotly\n",
    "def create_agent_animation(data, max_frames=100):\n",
    "    \"\"\"Create an interactive animation of agent movements.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "    max_frames (int): Maximum number of frames to include in the animation\n",
    "\n",
    "    Returns:\n",
    "    plotly.graph_objects.Figure: Interactive animation figure\n",
    "    \"\"\"\n",
    "    # Get unique timestamps and agent IDs\n",
    "    timestamps = sorted(data[\"timestamp\"].unique())\n",
    "\n",
    "    # Limit the number of frames if needed\n",
    "    if len(timestamps) > max_frames:\n",
    "        timestamps = timestamps[:max_frames]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = px.scatter(\n",
    "        data_frame=data[data[\"timestamp\"].isin(timestamps)],\n",
    "        x=\"x_position\",\n",
    "        y=\"y_position\",\n",
    "        animation_frame=\"timestamp\",\n",
    "        animation_group=\"agent_id\",\n",
    "        color=\"agent_id\",\n",
    "        size=\"energy\",\n",
    "        hover_name=\"agent_id\",\n",
    "        hover_data=[\"state\", \"success_rate\"],\n",
    "        title=\"Agent Movement Animation\",\n",
    "        labels={\"x_position\": \"X Position\", \"y_position\": \"Y Position\"},\n",
    "        range_x=[data[\"x_position\"].min() - 1, data[\"x_position\"].max() + 1],\n",
    "        range_y=[data[\"y_position\"].min() - 1, data[\"y_position\"].max() + 1],\n",
    "    )\n",
    "\n",
    "    # Customize the animation\n",
    "    fig.update_layout(autosize=True, width=900, height=700)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Execute visualization functions\n",
    "plot_agent_positions(agent_data)\n",
    "plot_agent_trajectories(agent_data)\n",
    "animation = create_agent_animation(agent_data)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0705492",
   "metadata": {},
   "source": [
    "## Analyze Agent Interactions\n",
    "\n",
    "This section focuses on visualizing interactions between agents, such as proximity, collisions, or other defined interaction metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f37023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distances between agents at each timestamp\n",
    "def calculate_agent_distances(data):\n",
    "    \"\"\"Calculate distances between all pairs of agents at each timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary mapping timestamps to distance matrices\n",
    "    \"\"\"\n",
    "    distances = {}\n",
    "\n",
    "    for timestamp in sorted(data[\"timestamp\"].unique()):\n",
    "        time_data = data[data[\"timestamp\"] == timestamp]\n",
    "\n",
    "        # Get positions of all agents\n",
    "        positions = time_data[[\"x_position\", \"y_position\"]].values\n",
    "\n",
    "        # Calculate pairwise distances\n",
    "        if len(positions) > 1:\n",
    "            dist_matrix = squareform(pdist(positions))\n",
    "            agent_ids = time_data[\"agent_id\"].values\n",
    "\n",
    "            # Create a DataFrame with agent IDs as indices and columns\n",
    "            dist_df = pd.DataFrame(dist_matrix, index=agent_ids, columns=agent_ids)\n",
    "\n",
    "            distances[timestamp] = dist_df\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "# Function to visualize agent proximity at a specific timestamp\n",
    "def plot_agent_proximity(data, timestamp=None, threshold=5.0):\n",
    "    \"\"\"Visualize agent proximity at a specific timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "    timestamp (int): Timestamp to analyze (if None, use the last timestamp)\n",
    "    threshold (float): Distance threshold for considering agents to be \"close\"\n",
    "    \"\"\"\n",
    "    if timestamp is None:\n",
    "        timestamp = data[\"timestamp\"].max()\n",
    "\n",
    "    # Filter data for the specific timestamp\n",
    "    time_data = data[data[\"timestamp\"] == timestamp]\n",
    "\n",
    "    # Get positions and calculate distances\n",
    "    positions = time_data[[\"x_position\", \"y_position\"]].values\n",
    "    agent_ids = time_data[\"agent_id\"].values\n",
    "\n",
    "    if len(positions) <= 1:\n",
    "        print(f\"Not enough agents at timestamp {timestamp} for proximity analysis\")\n",
    "        return\n",
    "\n",
    "    dist_matrix = squareform(pdist(positions))\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot agent positions\n",
    "    ax1.scatter(\n",
    "        time_data[\"x_position\"],\n",
    "        time_data[\"y_position\"],\n",
    "        c=time_data[\"agent_id\"],\n",
    "        s=100,\n",
    "        cmap=\"viridis\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Add lines between agents that are close to each other\n",
    "    for i in range(len(agent_ids)):\n",
    "        for j in range(i + 1, len(agent_ids)):\n",
    "            if dist_matrix[i, j] < threshold:\n",
    "                ax1.plot(\n",
    "                    [positions[i, 0], positions[j, 0]],\n",
    "                    [positions[i, 1], positions[j, 1]],\n",
    "                    \"r-\",\n",
    "                    alpha=0.5,\n",
    "                    linewidth=1.0,\n",
    "                )\n",
    "\n",
    "    ax1.set_xlabel(\"X Position\")\n",
    "    ax1.set_ylabel(\"Y Position\")\n",
    "    ax1.set_title(f\"Agent Proximity at Timestamp {timestamp}\")\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Plot distance matrix as a heatmap\n",
    "    sns.heatmap(\n",
    "        pd.DataFrame(dist_matrix, index=agent_ids, columns=agent_ids),\n",
    "        annot=True,\n",
    "        cmap=\"viridis_r\",\n",
    "        ax=ax2,\n",
    "    )\n",
    "    ax2.set_title(\"Distance Matrix Between Agents\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to analyze agent interaction patterns over time\n",
    "def analyze_interaction_patterns(data, threshold=5.0):\n",
    "    \"\"\"Analyze patterns of agent interactions over time.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Agent behavior data\n",
    "    threshold (float): Distance threshold for considering agents to be interacting\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Data frame with interaction metrics over time\n",
    "    \"\"\"\n",
    "    interaction_data = []\n",
    "\n",
    "    # Get all agent IDs\n",
    "    sorted(data[\"agent_id\"].unique())\n",
    "\n",
    "    # Analyze each timestamp\n",
    "    for timestamp in sorted(data[\"timestamp\"].unique()):\n",
    "        time_data = data[data[\"timestamp\"] == timestamp]\n",
    "\n",
    "        # Skip if not enough agents\n",
    "        if len(time_data) <= 1:\n",
    "            continue\n",
    "\n",
    "        # Calculate distances between agents\n",
    "        positions = time_data[[\"x_position\", \"y_position\"]].values\n",
    "        dist_matrix = squareform(pdist(positions))\n",
    "        agent_ids = time_data[\"agent_id\"].values\n",
    "\n",
    "        # Count interactions for each agent\n",
    "        for i, agent_id in enumerate(agent_ids):\n",
    "            # Count how many other agents are within threshold\n",
    "            interaction_count = (\n",
    "                np.sum(dist_matrix[i, :] < threshold) - 1\n",
    "            )  # -1 to exclude self\n",
    "\n",
    "            # Get agent state\n",
    "            agent_state = time_data[time_data[\"agent_id\"] == agent_id][\"state\"].values[\n",
    "                0\n",
    "            ]\n",
    "\n",
    "            interaction_data.append(\n",
    "                {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"agent_id\": agent_id,\n",
    "                    \"interaction_count\": interaction_count,\n",
    "                    \"state\": agent_state,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    interaction_df = pd.DataFrame(interaction_data)\n",
    "    return interaction_df\n",
    "\n",
    "\n",
    "# Function to visualize interaction patterns\n",
    "def plot_interaction_patterns(interaction_df):\n",
    "    \"\"\"Visualize patterns of agent interactions over time.\n",
    "\n",
    "    Parameters:\n",
    "    interaction_df (pandas.DataFrame): Output from analyze_interaction_patterns\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Get all agent IDs\n",
    "    agent_ids = sorted(interaction_df[\"agent_id\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(agent_ids)))\n",
    "\n",
    "    # Plot interaction count for each agent over time\n",
    "    for i, agent_id in enumerate(agent_ids):\n",
    "        agent_data = interaction_df[interaction_df[\"agent_id\"] == agent_id]\n",
    "        plt.plot(\n",
    "            agent_data[\"timestamp\"],\n",
    "            agent_data[\"interaction_count\"],\n",
    "            \"-o\",\n",
    "            linewidth=1.5,\n",
    "            markersize=4,\n",
    "            alpha=0.7,\n",
    "            color=colors[i % len(colors)],\n",
    "            label=f\"Agent {agent_id}\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Interaction Count\")\n",
    "    plt.title(\"Agent Interactions Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot interaction count by agent state\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"state\", y=\"interaction_count\", data=interaction_df)\n",
    "    plt.title(\"Interaction Count by Agent State\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Execute interaction analysis\n",
    "agent_distances = calculate_agent_distances(agent_data)\n",
    "plot_agent_proximity(agent_data)\n",
    "interaction_df = analyze_interaction_patterns(agent_data)\n",
    "plot_interaction_patterns(interaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8adec",
   "metadata": {},
   "source": [
    "## Customize Visualization Parameters\n",
    "\n",
    "This section provides functionality to customize the visualization parameters, allowing for more flexible analysis of agent behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2303b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentVisualizer:\n",
    "    \"\"\"Class for customizable agent behavior visualization.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Initialize the visualizer with agent data.\n",
    "\n",
    "        Parameters:\n",
    "        data (pandas.DataFrame): Agent behavior data\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.timestamps = sorted(data[\"timestamp\"].unique())\n",
    "        self.agent_ids = sorted(data[\"agent_id\"].unique())\n",
    "        self.color_map = \"viridis\"\n",
    "        self.marker_size = 100\n",
    "        self.line_width = 1.5\n",
    "        self.alpha = 0.7\n",
    "        self.grid_alpha = 0.5\n",
    "\n",
    "    def set_color_map(self, color_map):\n",
    "        \"\"\"Set the colormap used for visualizations.\"\"\"\n",
    "        self.color_map = color_map\n",
    "        return self\n",
    "\n",
    "    def set_marker_size(self, marker_size):\n",
    "        \"\"\"Set the marker size for agents.\"\"\"\n",
    "        self.marker_size = marker_size\n",
    "        return self\n",
    "\n",
    "    def set_line_width(self, line_width):\n",
    "        \"\"\"Set the line width for trajectory plots.\"\"\"\n",
    "        self.line_width = line_width\n",
    "        return self\n",
    "\n",
    "    def set_alpha(self, alpha):\n",
    "        \"\"\"Set the transparency level for visualizations.\"\"\"\n",
    "        self.alpha = alpha\n",
    "        return self\n",
    "\n",
    "    def plot_agent_positions(\n",
    "        self, timestamp=None, figsize=(10, 8), selected_agents=None, variable_color=None\n",
    "    ):\n",
    "        \"\"\"Plot agent positions at a specific timestamp with customizable parameters.\n",
    "\n",
    "        Parameters:\n",
    "        timestamp (int): Timestamp to visualize (None = last timestamp)\n",
    "        figsize (tuple): Figure size as (width, height)\n",
    "        selected_agents (list): List of agent IDs to include (None = all agents)\n",
    "        variable_color (str): Name of the variable to use for coloring (None = agent_id)\n",
    "        \"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = self.timestamps[-1]\n",
    "\n",
    "        # Filter data for the specific timestamp\n",
    "        time_data = self.data[self.data[\"timestamp\"] == timestamp]\n",
    "\n",
    "        # Filter for selected agents if specified\n",
    "        if selected_agents is not None:\n",
    "            time_data = time_data[time_data[\"agent_id\"].isin(selected_agents)]\n",
    "\n",
    "        if len(time_data) == 0:\n",
    "            print(f\"No agents found at timestamp {timestamp}\")\n",
    "            return\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # Choose the color variable\n",
    "        color_var = variable_color if variable_color is not None else \"agent_id\"\n",
    "\n",
    "        # Create a scatter plot of agent positions\n",
    "        scatter = plt.scatter(\n",
    "            time_data[\"x_position\"],\n",
    "            time_data[\"y_position\"],\n",
    "            c=time_data[color_var],\n",
    "            s=self.marker_size,\n",
    "            cmap=self.color_map,\n",
    "            alpha=self.alpha,\n",
    "        )\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        title = f\"Agent Positions at Timestamp {timestamp}\"\n",
    "        if selected_agents is not None:\n",
    "            title += f\" (Selected Agents: {selected_agents})\"\n",
    "        plt.title(title)\n",
    "\n",
    "        # Add a colorbar\n",
    "        plt.colorbar(scatter, label=color_var)\n",
    "\n",
    "        # Display agent IDs as text labels\n",
    "        for _, row in time_data.iterrows():\n",
    "            plt.annotate(\n",
    "                f\"{int(row['agent_id'])}\",\n",
    "                (row[\"x_position\"], row[\"y_position\"]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 5),\n",
    "                ha=\"center\",\n",
    "            )\n",
    "\n",
    "        plt.grid(True, linestyle=\"--\", alpha=self.grid_alpha)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_agent_trajectories(\n",
    "        self, agent_ids=None, time_range=None, figsize=(12, 10), variable_color=None\n",
    "    ):\n",
    "        \"\"\"Plot agent trajectories with customized parameters.\n",
    "\n",
    "        Parameters:\n",
    "        agent_ids (list): List of agent IDs to include (None = all agents)\n",
    "        time_range (tuple): (start_time, end_time) to limit the time range\n",
    "        figsize (tuple): Figure size as (width, height)\n",
    "        variable_color (str): Name of variable to use for coloring (None = agent_id)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # Select agents to visualize\n",
    "        if agent_ids is None:\n",
    "            agent_ids = self.agent_ids\n",
    "\n",
    "        # Filter by time range if specified\n",
    "        data = self.data\n",
    "        if time_range is not None:\n",
    "            start_time, end_time = time_range\n",
    "            data = data[\n",
    "                (data[\"timestamp\"] >= start_time) & (data[\"timestamp\"] <= end_time)\n",
    "            ]\n",
    "\n",
    "        # Determine color mapping\n",
    "        if variable_color is None:\n",
    "            # One color per agent\n",
    "            colors = plt.cm.rainbow(np.linspace(0, 1, len(agent_ids)))\n",
    "\n",
    "            for i, agent_id in enumerate(agent_ids):\n",
    "                agent_data = data[data[\"agent_id\"] == agent_id]\n",
    "                plt.plot(\n",
    "                    agent_data[\"x_position\"],\n",
    "                    agent_data[\"y_position\"],\n",
    "                    \"-o\",\n",
    "                    linewidth=self.line_width,\n",
    "                    markersize=4,\n",
    "                    alpha=self.alpha,\n",
    "                    color=colors[i],\n",
    "                    label=f\"Agent {agent_id}\",\n",
    "                )\n",
    "        else:\n",
    "            # Color based on a variable\n",
    "            for agent_id in agent_ids:\n",
    "                agent_data = data[data[\"agent_id\"] == agent_id]\n",
    "\n",
    "                points = plt.scatter(\n",
    "                    agent_data[\"x_position\"],\n",
    "                    agent_data[\"y_position\"],\n",
    "                    c=agent_data[variable_color],\n",
    "                    s=self.marker_size / 2,\n",
    "                    cmap=self.color_map,\n",
    "                    alpha=self.alpha,\n",
    "                    label=f\"Agent {agent_id}\",\n",
    "                )\n",
    "\n",
    "                # Connect points with lines\n",
    "                plt.plot(\n",
    "                    agent_data[\"x_position\"],\n",
    "                    agent_data[\"y_position\"],\n",
    "                    \"-\",\n",
    "                    linewidth=self.line_width / 2,\n",
    "                    alpha=self.alpha / 2,\n",
    "                    color=\"gray\",\n",
    "                )\n",
    "\n",
    "            plt.colorbar(points, label=variable_color)\n",
    "\n",
    "        # Set plot attributes\n",
    "        title = \"Agent Trajectories\"\n",
    "        if time_range is not None:\n",
    "            title += f\" (Time: {time_range[0]}-{time_range[1]})\"\n",
    "\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", alpha=self.grid_alpha)\n",
    "        plt.show()\n",
    "\n",
    "    def create_interactive_visualization(self, max_frames=100):\n",
    "        \"\"\"Create an interactive visualization with customizable parameters.\n",
    "\n",
    "        Parameters:\n",
    "        max_frames (int): Maximum number of frames to include\n",
    "\n",
    "        Returns:\n",
    "        plotly.graph_objects.Figure: Interactive visualization\n",
    "        \"\"\"\n",
    "        # Limit the number of timestamps if needed\n",
    "        timestamps = self.timestamps\n",
    "        if len(timestamps) > max_frames:\n",
    "            timestamps = timestamps[:max_frames]\n",
    "\n",
    "        # Create the figure\n",
    "        fig = px.scatter(\n",
    "            data_frame=self.data[self.data[\"timestamp\"].isin(timestamps)],\n",
    "            x=\"x_position\",\n",
    "            y=\"y_position\",\n",
    "            animation_frame=\"timestamp\",\n",
    "            animation_group=\"agent_id\",\n",
    "            color=\"agent_id\",\n",
    "            size=\"energy\",\n",
    "            hover_name=\"agent_id\",\n",
    "            hover_data=[\"state\", \"success_rate\"],\n",
    "            title=\"Interactive Agent Movement Visualization\",\n",
    "            labels={\"x_position\": \"X Position\", \"y_position\": \"Y Position\"},\n",
    "            range_x=[\n",
    "                self.data[\"x_position\"].min() - 1,\n",
    "                self.data[\"x_position\"].max() + 1,\n",
    "            ],\n",
    "            range_y=[\n",
    "                self.data[\"y_position\"].min() - 1,\n",
    "                self.data[\"y_position\"].max() + 1,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Customize the visualization\n",
    "        fig.update_traces(marker=dict(line=dict(width=2, color=\"DarkSlateGrey\")))\n",
    "\n",
    "        fig.update_layout(\n",
    "            autosize=True,\n",
    "            width=900,\n",
    "            height=700,\n",
    "            plot_bgcolor=\"white\",\n",
    "            legend_title_text=\"Agent ID\",\n",
    "        )\n",
    "\n",
    "        # Add path traces to show trajectories\n",
    "        for agent_id in self.agent_ids:\n",
    "            agent_data = self.data[self.data[\"agent_id\"] == agent_id]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=agent_data[\"x_position\"],\n",
    "                    y=agent_data[\"y_position\"],\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=1, color=\"rgba(0,0,0,0.3)\"),\n",
    "                    showlegend=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n",
    "# Example usage of the customizable visualizer\n",
    "visualizer = AgentVisualizer(agent_data)\n",
    "\n",
    "# Example 1: Basic position plot with default settings\n",
    "visualizer.plot_agent_positions()\n",
    "\n",
    "# Example 2: Customized position plot with energy as the color variable\n",
    "visualizer.set_color_map(\"plasma\").set_marker_size(150).plot_agent_positions(\n",
    "    variable_color=\"energy\"\n",
    ")\n",
    "\n",
    "# Example 3: Customized trajectory plot for specific agents\n",
    "visualizer.set_color_map(\"viridis\").set_line_width(2).plot_agent_trajectories(\n",
    "    agent_ids=[1, 2, 3], time_range=(10, 50)\n",
    ")\n",
    "\n",
    "# Example 4: Trajectory plot colored by state\n",
    "visualizer.set_alpha(0.8).plot_agent_trajectories(variable_color=\"success_rate\")\n",
    "\n",
    "# Example 5: Create an interactive visualization\n",
    "interactive_viz = visualizer.create_interactive_visualization(max_frames=50)\n",
    "interactive_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed5e2b",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "In this notebook, we've implemented visualizations for agent behavior in a SAT solver environment. The key components include:\n",
    "\n",
    "1. **Data Loading and Preparation**: Functions to load and prepare agent behavior data\n",
    "2. **Movement Visualization**: Static, trajectory, and animated visualizations of agent movements\n",
    "3. **Interaction Analysis**: Tools for identifying and visualizing agent interactions like proximity and collisions\n",
    "4. **Customizable Visualization**: A flexible visualization class to customize parameters like colors, time intervals, and markers\n",
    "\n",
    "These visualizations provide insights into how agents move and interact in the environment, helping to understand the behavior patterns of the hybrid SAT solver. By analyzing these patterns, we can potentially identify areas for optimization and improvement in the solver's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d59d0",
   "metadata": {},
   "source": [
    "## Data Processing Module\n",
    "\n",
    "This section contains functions for processing data from the StructuredLogger and preparing it for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to path to import local modules\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "# Import the Logger from symbolicgym\n",
    "try:\n",
    "    from symbolicgym.utils.logging import Logger\n",
    "\n",
    "    print(\"Successfully imported Logger from symbolicgym\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing Logger: {e}\")\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Process data from Logger into visualization-ready formats.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.metadata = None\n",
    "        self.variable_assignments = None\n",
    "        self.clause_counts = None\n",
    "        self.agent_behavior = None\n",
    "        self.agent_decisions = None\n",
    "        self.rewards = None\n",
    "\n",
    "    def load_from_metadata(self, metadata_file):\n",
    "        \"\"\"Load all data using a visualization metadata file.\"\"\"\n",
    "        try:\n",
    "            # Load the metadata file\n",
    "            with open(metadata_file) as f:\n",
    "                self.metadata = json.load(f)\n",
    "\n",
    "            print(f\"Loaded metadata from {metadata_file}\")\n",
    "\n",
    "            # Load data files according to metadata\n",
    "            data_files = self.metadata[\"data_files\"]\n",
    "\n",
    "            if \"variable_assignments\" in data_files:\n",
    "                self.variable_assignments = pd.read_csv(\n",
    "                    data_files[\"variable_assignments\"]\n",
    "                )\n",
    "                print(\n",
    "                    f\"Loaded variable assignments: {self.variable_assignments.shape[0]} rows\"\n",
    "                )\n",
    "\n",
    "            if \"clause_counts\" in data_files:\n",
    "                self.clause_counts = pd.read_csv(data_files[\"clause_counts\"])\n",
    "                print(f\"Loaded clause counts: {self.clause_counts.shape[0]} rows\")\n",
    "\n",
    "            if \"agent_behavior\" in data_files:\n",
    "                self.agent_behavior = pd.read_csv(data_files[\"agent_behavior\"])\n",
    "                print(f\"Loaded agent behavior: {self.agent_behavior.shape[0]} rows\")\n",
    "\n",
    "            if \"agent_decisions\" in data_files:\n",
    "                self.agent_decisions = pd.read_csv(data_files[\"agent_decisions\"])\n",
    "                print(f\"Loaded agent decisions: {self.agent_decisions.shape[0]} rows\")\n",
    "\n",
    "            if \"rewards\" in data_files:\n",
    "                self.rewards = pd.read_csv(data_files[\"rewards\"])\n",
    "                print(f\"Loaded rewards: {self.rewards.shape[0]} rows\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_from_experiment(self, experiment_name, log_dir=\"logs\"):\n",
    "        \"\"\"Load data for a specific experiment name.\"\"\"\n",
    "        metadata_file = os.path.join(log_dir, f\"{experiment_name}_viz_metadata.json\")\n",
    "        return self.load_from_metadata(metadata_file)\n",
    "\n",
    "    def load_from_logger(self, logger):\n",
    "        \"\"\"Load data directly from a Logger instance.\"\"\"\n",
    "        try:\n",
    "            # Get dataframes from logger\n",
    "            dfs = logger.get_dataframes()\n",
    "\n",
    "            self.agent_decisions = dfs[\"agent_decisions\"]\n",
    "            self.variable_assignments = dfs[\"variable_assignments\"]\n",
    "            self.rewards = dfs[\"rewards\"]\n",
    "            self.clause_counts = dfs[\"clause_counts\"]\n",
    "            self.agent_behavior = dfs[\"agent_states\"]\n",
    "\n",
    "            print(\"Loaded data directly from logger:\")\n",
    "            print(f\"  - Agent decisions: {len(self.agent_decisions)} rows\")\n",
    "            print(f\"  - Variable assignments: {len(self.variable_assignments)} rows\")\n",
    "            print(f\"  - Rewards: {len(self.rewards)} rows\")\n",
    "            print(f\"  - Clause counts: {len(self.clause_counts)} rows\")\n",
    "            print(f\"  - Agent behavior: {len(self.agent_behavior)} rows\")\n",
    "\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data from logger: {e}\")\n",
    "            return False\n",
    "\n",
    "    def prepare_variable_assignment_heatmap_data(self):\n",
    "        \"\"\"Prepare variable assignment data for heatmap visualization.\"\"\"\n",
    "        if self.variable_assignments is None or len(self.variable_assignments) == 0:\n",
    "            print(\"No variable assignment data available\")\n",
    "            return None\n",
    "\n",
    "        # Convert the data to a format suitable for a heatmap\n",
    "        # We want a matrix where rows are variables, columns are timestamps\n",
    "        try:\n",
    "            # First get the unique episodes, variables and timestamps\n",
    "            episodes = sorted(self.variable_assignments[\"episode\"].unique())\n",
    "            variables = sorted(self.variable_assignments[\"variable_idx\"].unique())\n",
    "            timestamps = sorted(self.variable_assignments[\"timestamp\"].unique())\n",
    "\n",
    "            # Create heatmap data for each episode\n",
    "            heatmap_data = {}\n",
    "\n",
    "            for episode in episodes:\n",
    "                # Filter data for this episode\n",
    "                episode_data = self.variable_assignments[\n",
    "                    self.variable_assignments[\"episode\"] == episode\n",
    "                ]\n",
    "\n",
    "                # Create a DataFrame with variables as rows and timestamps as columns\n",
    "                heatmap_df = pd.DataFrame(\n",
    "                    index=variables, columns=timestamps, dtype=float\n",
    "                )\n",
    "\n",
    "                # Fill in the values from the variable assignments\n",
    "                for _, row in episode_data.iterrows():\n",
    "                    heatmap_df.at[row[\"variable_idx\"], row[\"timestamp\"]] = row[\n",
    "                        \"assignment\"\n",
    "                    ]\n",
    "\n",
    "                # Forward fill to handle missing values (keep the previous assignment)\n",
    "                heatmap_df = heatmap_df.fillna(method=\"ffill\", axis=1)\n",
    "\n",
    "                # Store the heatmap data for this episode\n",
    "                heatmap_data[episode] = heatmap_df\n",
    "\n",
    "            return heatmap_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing heatmap data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_clause_satisfaction_data(self):\n",
    "        \"\"\"Prepare clause satisfaction data for line plots.\"\"\"\n",
    "        if self.clause_counts is None or len(self.clause_counts) == 0:\n",
    "            print(\"No clause count data available\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Group by episode and timestamp, aggregate the satisfaction rate\n",
    "            if \"satisfaction_rate\" in self.clause_counts.columns:\n",
    "                grouped = (\n",
    "                    self.clause_counts.groupby([\"episode\", \"timestamp\"])[\n",
    "                        \"satisfaction_rate\"\n",
    "                    ]\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "            else:\n",
    "                # Calculate satisfaction rate if not available\n",
    "                self.clause_counts[\"satisfaction_rate\"] = (\n",
    "                    self.clause_counts[\"satisfied_count\"]\n",
    "                    / self.clause_counts[\"total_count\"]\n",
    "                )\n",
    "                grouped = (\n",
    "                    self.clause_counts.groupby([\"episode\", \"timestamp\"])[\n",
    "                        \"satisfaction_rate\"\n",
    "                    ]\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "\n",
    "            return grouped\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing clause satisfaction data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_reward_data(self):\n",
    "        \"\"\"Prepare reward data for line plots.\"\"\"\n",
    "        if self.rewards is None or len(self.rewards) == 0:\n",
    "            print(\"No reward data available\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Group by episode and step, calculate mean reward\n",
    "            if \"step\" in self.rewards.columns:\n",
    "                grouped = (\n",
    "                    self.rewards.groupby([\"episode\", \"step\"])[\"reward\"]\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "            elif \"timestamp\" in self.rewards.columns:\n",
    "                grouped = (\n",
    "                    self.rewards.groupby([\"episode\", \"timestamp\"])[\"reward\"]\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                )\n",
    "                grouped = grouped.rename(columns={\"timestamp\": \"step\"})\n",
    "            else:\n",
    "                print(\"Reward data doesn't have step or timestamp column\")\n",
    "                return None\n",
    "\n",
    "            # Calculate cumulative rewards per episode\n",
    "            episodes = sorted(grouped[\"episode\"].unique())\n",
    "            cumulative_rewards = {}\n",
    "\n",
    "            for episode in episodes:\n",
    "                episode_data = grouped[grouped[\"episode\"] == episode]\n",
    "                cumulative_rewards[episode] = episode_data[\"reward\"].cumsum()\n",
    "\n",
    "            return {\"rewards\": grouped, \"cumulative\": cumulative_rewards}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing reward data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_agent_state_data(self):\n",
    "        \"\"\"Prepare agent state data for visualization.\"\"\"\n",
    "        if self.agent_behavior is None or len(self.agent_behavior) == 0:\n",
    "            print(\"No agent behavior data available\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Group by agent and timestamp\n",
    "            agent_states = {}\n",
    "\n",
    "            for agent_id in sorted(self.agent_behavior[\"agent_id\"].unique()):\n",
    "                agent_data = self.agent_behavior[\n",
    "                    self.agent_behavior[\"agent_id\"] == agent_id\n",
    "                ]\n",
    "                agent_states[agent_id] = agent_data.sort_values(\"timestamp\")\n",
    "\n",
    "            return agent_states\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing agent state data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_action_entropy(self):\n",
    "        \"\"\"Calculate action entropy over time to detect policy convergence.\"\"\"\n",
    "        if self.agent_decisions is None or len(self.agent_decisions) == 0:\n",
    "            print(\"No agent decision data available\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            import scipy.stats as stats\n",
    "\n",
    "            # Group by agent_id, variable_id and count actions\n",
    "            if \"variable_id\" in self.agent_decisions.columns:\n",
    "                variable_col = \"variable_id\"\n",
    "            elif \"variable_idx\" in self.agent_decisions.columns:\n",
    "                variable_col = \"variable_idx\"\n",
    "            else:\n",
    "                print(\"Cannot find variable identifier column\")\n",
    "                return None\n",
    "\n",
    "            # Group by episode and time window\n",
    "            if \"step\" in self.agent_decisions.columns:\n",
    "                step_col = \"step\"\n",
    "            elif \"timestamp\" in self.agent_decisions.columns:\n",
    "                step_col = \"timestamp\"\n",
    "            else:\n",
    "                print(\"Cannot find step/timestamp column\")\n",
    "                return None\n",
    "\n",
    "            # Add a window column for entropy calculation\n",
    "            window_size = 10  # Calculate entropy over 10-step windows\n",
    "            self.agent_decisions[\"window\"] = (\n",
    "                self.agent_decisions[step_col] // window_size\n",
    "            ) * window_size\n",
    "\n",
    "            entropy_data = []\n",
    "\n",
    "            # Calculate entropy for each agent, episode and window\n",
    "            for agent_id in self.agent_decisions[\"agent_id\"].unique():\n",
    "                agent_data = self.agent_decisions[\n",
    "                    self.agent_decisions[\"agent_id\"] == agent_id\n",
    "                ]\n",
    "\n",
    "                for episode in agent_data[\"episode\"].unique():\n",
    "                    episode_data = agent_data[agent_data[\"episode\"] == episode]\n",
    "\n",
    "                    for window in episode_data[\"window\"].unique():\n",
    "                        window_data = episode_data[episode_data[\"window\"] == window]\n",
    "\n",
    "                        # Count actions (0 or 1) for each variable\n",
    "                        action_counts = (\n",
    "                            window_data.groupby(variable_col)[\"action\"]\n",
    "                            .value_counts()\n",
    "                            .unstack(fill_value=0)\n",
    "                        )\n",
    "\n",
    "                        # Calculate entropy for each variable\n",
    "                        entropies = []\n",
    "                        for _, row in action_counts.iterrows():\n",
    "                            counts = row.values\n",
    "                            if sum(counts) > 0:\n",
    "                                # Normalize to get probabilities\n",
    "                                probs = counts / sum(counts)\n",
    "                                # Calculate entropy\n",
    "                                entropy = stats.entropy(probs, base=2)\n",
    "                                entropies.append(entropy)\n",
    "\n",
    "                        # Average entropy across variables\n",
    "                        if entropies:\n",
    "                            avg_entropy = sum(entropies) / len(entropies)\n",
    "                        else:\n",
    "                            avg_entropy = 0\n",
    "\n",
    "                        entropy_data.append(\n",
    "                            {\n",
    "                                \"agent_id\": agent_id,\n",
    "                                \"episode\": episode,\n",
    "                                \"window\": window,\n",
    "                                \"entropy\": avg_entropy,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            return pd.DataFrame(entropy_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating action entropy: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Test with sample data\n",
    "# Uncomment and modify the path to load data from a specific experiment\n",
    "# processor.load_from_experiment(\"my_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d36a63",
   "metadata": {},
   "source": [
    "## Integration Script: Run Solver and Generate Visualizations\n",
    "\n",
    "This section provides a complete pipeline to run the SAT solver and automatically generate visualizations from the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the parent directory to path to import solver modules\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "# Import the Logger from symbolicgym\n",
    "try:\n",
    "    from symbolicgym.utils.logging import Logger\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing Logger: {e}\")\n",
    "\n",
    "\n",
    "class SATSolverSimulator:\n",
    "    \"\"\"Simulation of a SAT solver for visualization testing.\"\"\"\n",
    "\n",
    "    def __init__(self, num_variables=20, num_clauses=80, num_episodes=5, max_steps=100):\n",
    "        \"\"\"Initialize the SAT solver simulator.\"\"\"\n",
    "        self.num_variables = num_variables\n",
    "        self.num_clauses = num_clauses\n",
    "        self.num_episodes = num_episodes\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # Create a logger (using Logger class)\n",
    "        self.logger = Logger(\n",
    "            experiment_name=f\"sat_sim_{num_variables}vars_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            visualize_ready=True,\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the simulation.\"\"\"\n",
    "        print(\n",
    "            f\"Starting simulation with {self.num_variables} variables and {self.num_clauses} clauses\"\n",
    "        )\n",
    "\n",
    "        # Run episodes\n",
    "        for episode in range(self.num_episodes):\n",
    "            print(f\"Episode {episode + 1}/{self.num_episodes}\")\n",
    "            self.run_episode(episode)\n",
    "\n",
    "        # Finalize logging\n",
    "        metadata_file = self.logger.finalize()\n",
    "        print(f\"Simulation complete. Metadata saved to: {metadata_file}\")\n",
    "\n",
    "        return metadata_file\n",
    "\n",
    "    def run_episode(self, episode):\n",
    "        \"\"\"Run a single episode.\"\"\"\n",
    "        # Initialize agent state\n",
    "        agent_state = {\n",
    "            \"state\": \"exploring\",\n",
    "            \"energy\": 100.0,\n",
    "            \"success_rate\": 0.5,\n",
    "            \"x_position\": 0.0,\n",
    "            \"y_position\": 0.0,\n",
    "        }\n",
    "\n",
    "        # Initialize variable assignments\n",
    "        assignments = [-1] * self.num_variables  # -1 = unassigned\n",
    "\n",
    "        # Track satisfied clauses\n",
    "        satisfied_count = 0\n",
    "        total_count = self.num_clauses\n",
    "\n",
    "        # Log initial variable assignments\n",
    "        for var_idx in range(self.num_variables):\n",
    "            self.logger.log_variable_assignment(\n",
    "                0, var_idx, -1, agent_id=0, episode=episode\n",
    "            )\n",
    "\n",
    "        # Main episode loop\n",
    "        for step in range(1, self.max_steps + 1):\n",
    "            # Choose a variable to assign\n",
    "            var_idx = self._choose_variable(assignments)\n",
    "\n",
    "            # Choose an action (0 or 1)\n",
    "            action = random.choice([0, 1])\n",
    "\n",
    "            # Update assignments\n",
    "            assignments[var_idx] = action\n",
    "\n",
    "            # Update satisfied clauses\n",
    "            old_satisfied = satisfied_count\n",
    "            satisfied_count = self._update_satisfied_count(assignments)\n",
    "\n",
    "            # Calculate reward based on change in satisfied clauses\n",
    "            reward = (satisfied_count - old_satisfied) / total_count\n",
    "\n",
    "            # Update agent state\n",
    "            agent_state = self._update_agent_state(agent_state, step, reward)\n",
    "\n",
    "            # Log the agent decision\n",
    "            self.logger.log_agent_decision(\n",
    "                episode=episode,\n",
    "                step=step,\n",
    "                agent_id=0,\n",
    "                variable_id=var_idx,\n",
    "                action=action,\n",
    "                activity_score=random.random(),\n",
    "            )\n",
    "\n",
    "            # Log the reward\n",
    "            self.logger.log_reward(\n",
    "                episode=episode,\n",
    "                step=step,\n",
    "                reward=reward,\n",
    "                clause_satisfaction=satisfied_count,\n",
    "                conflict_count=total_count - satisfied_count,\n",
    "                agent_id=0,\n",
    "            )\n",
    "\n",
    "            # Log agent state\n",
    "            self.logger.log_agent_state(\n",
    "                step=step, state_dict=agent_state, agent_id=0, episode=episode\n",
    "            )\n",
    "\n",
    "            # Check if all clauses are satisfied\n",
    "            if satisfied_count == total_count:\n",
    "                print(f\"Episode {episode}: All clauses satisfied at step {step}!\")\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} completed with {satisfied_count}/{total_count} clauses satisfied\"\n",
    "        )\n",
    "\n",
    "    def _choose_variable(self, assignments):\n",
    "        \"\"\"Choose a variable to assign.\"\"\"\n",
    "        # Randomly choose an unassigned variable if available\n",
    "        unassigned = [i for i, val in enumerate(assignments) if val == -1]\n",
    "        if unassigned:\n",
    "            return random.choice(unassigned)\n",
    "        else:\n",
    "            # If all variables are assigned, choose one to reassign\n",
    "            return random.randint(0, self.num_variables - 1)\n",
    "\n",
    "    def _update_satisfied_count(self, assignments):\n",
    "        \"\"\"Update the count of satisfied clauses.\"\"\"\n",
    "        # Simulate a random increase in satisfied clauses\n",
    "        assigned_count = sum(1 for a in assignments if a != -1)\n",
    "        assignment_ratio = assigned_count / self.num_variables\n",
    "\n",
    "        # Simulate a realistic satisfaction curve:\n",
    "        # - Low at the beginning\n",
    "        # - Increases as more variables are assigned\n",
    "        # - Flattens out as we approach full assignment\n",
    "        base_satisfaction = 0.6 * assignment_ratio * self.num_clauses\n",
    "        noise = 0.1 * self.num_clauses * (random.random() - 0.5)\n",
    "\n",
    "        # Add a bias toward the end to simulate success\n",
    "        if assignment_ratio > 0.8:\n",
    "            bias = 0.3 * (assignment_ratio - 0.8) / 0.2 * self.num_clauses\n",
    "        else:\n",
    "            bias = 0\n",
    "\n",
    "        satisfied = int(base_satisfaction + noise + bias)\n",
    "        satisfied = max(0, min(satisfied, self.num_clauses))  # Clamp\n",
    "\n",
    "        return satisfied\n",
    "\n",
    "    def _update_agent_state(self, state, step, reward):\n",
    "        \"\"\"Update the agent state.\"\"\"\n",
    "        new_state = state.copy()\n",
    "\n",
    "        # Update energy (decreases over time, increases with positive rewards)\n",
    "        new_state[\"energy\"] = max(0, min(100, state[\"energy\"] - 1 + reward * 20))\n",
    "\n",
    "        # Update success rate (moving average)\n",
    "        if reward > 0:\n",
    "            new_state[\"success_rate\"] = 0.9 * state[\"success_rate\"] + 0.1 * 1.0\n",
    "        else:\n",
    "            new_state[\"success_rate\"] = 0.9 * state[\"success_rate\"] + 0.1 * 0.0\n",
    "\n",
    "        # Update position (random walk with bias)\n",
    "        new_state[\"x_position\"] = (\n",
    "            state[\"x_position\"] + 0.1 * np.random.normal() + 0.05 * reward\n",
    "        )\n",
    "        new_state[\"y_position\"] = (\n",
    "            state[\"y_position\"] + 0.1 * np.random.normal() + 0.05 * reward\n",
    "        )\n",
    "\n",
    "        # Update state based on energy and success rate\n",
    "        if new_state[\"energy\"] < 20:\n",
    "            new_state[\"state\"] = \"exhausted\"\n",
    "        elif new_state[\"success_rate\"] > 0.7:\n",
    "            new_state[\"state\"] = \"exploiting\"\n",
    "        elif step < 10:\n",
    "            new_state[\"state\"] = \"exploring\"\n",
    "        else:\n",
    "            new_state[\"state\"] = random.choice(\n",
    "                [\"exploring\", \"exploiting\", \"backtracking\"]\n",
    "            )\n",
    "\n",
    "        return new_state\n",
    "\n",
    "\n",
    "# Function to run the solver and generate visualizations\n",
    "def run_solver_and_visualize(\n",
    "    num_variables=20, num_clauses=80, num_episodes=5, max_steps=100\n",
    "):\n",
    "    \"\"\"Run the SAT solver and generate visualizations.\"\"\"\n",
    "    # Run the solver\n",
    "    simulator = SATSolverSimulator(\n",
    "        num_variables=num_variables,\n",
    "        num_clauses=num_clauses,\n",
    "        num_episodes=num_episodes,\n",
    "        max_steps=max_steps,\n",
    "    )\n",
    "\n",
    "    metadata_file = simulator.run()\n",
    "\n",
    "    # Process the data\n",
    "    processor = DataProcessor()\n",
    "    if processor.load_from_metadata(metadata_file):\n",
    "        print(\"Data loaded successfully for visualization\")\n",
    "\n",
    "        # Return the processor for visualization\n",
    "        return processor\n",
    "    else:\n",
    "        print(\"Failed to load data for visualization\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Uncomment to run a simulation and visualization\n",
    "# processor = run_solver_and_visualize(num_variables=30, num_clauses=120, num_episodes=3, max_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ae70f",
   "metadata": {},
   "source": [
    "## Example Usage: Full Pipeline Demonstration\n",
    "\n",
    "This section demonstrates the complete pipeline from running the solver to generating visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a SAT solver simulation and collect data\n",
    "processor = run_solver_and_visualize(\n",
    "    num_variables=25,  # Number of variables in the SAT problem\n",
    "    num_clauses=100,  # Number of clauses\n",
    "    num_episodes=3,  # Number of solving episodes\n",
    "    max_steps=40,  # Maximum steps per episode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations based on the collected data\n",
    "if processor is not None:\n",
    "    # 1. Visualize variable assignments as a heatmap\n",
    "    heatmap_data = processor.prepare_variable_assignment_heatmap_data()\n",
    "\n",
    "    if heatmap_data:\n",
    "        # Plot heatmap for the first episode\n",
    "        episode = list(heatmap_data.keys())[0]\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(\n",
    "            heatmap_data[episode],\n",
    "            cmap=[\n",
    "                \"#FFFFFF\",\n",
    "                \"#FFA500\",\n",
    "                \"#0000FF\",\n",
    "            ],  # White (unassigned), Orange (False), Blue (True)\n",
    "            cbar_kws={\"label\": \"Assignment\"},\n",
    "        )\n",
    "        plt.title(f\"Variable Assignments Over Time (Episode {episode})\")\n",
    "        plt.xlabel(\"Timestamp\")\n",
    "        plt.ylabel(\"Variable Index\")\n",
    "        plt.show()\n",
    "\n",
    "    # 2. Visualize clause satisfaction over time\n",
    "    satisfaction_data = processor.prepare_clause_satisfaction_data()\n",
    "\n",
    "    if satisfaction_data is not None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for episode in sorted(satisfaction_data[\"episode\"].unique()):\n",
    "            episode_data = satisfaction_data[satisfaction_data[\"episode\"] == episode]\n",
    "            plt.plot(\n",
    "                episode_data[\"timestamp\"],\n",
    "                episode_data[\"satisfaction_rate\"],\n",
    "                \"-o\",\n",
    "                markersize=4,\n",
    "                label=f\"Episode {episode}\",\n",
    "            )\n",
    "\n",
    "        plt.title(\"Clause Satisfaction Rate Over Time\")\n",
    "        plt.xlabel(\"Timestamp\")\n",
    "        plt.ylabel(\"Satisfaction Rate\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "    # 3. Visualize agent behavior\n",
    "    agent_states = processor.prepare_agent_state_data()\n",
    "\n",
    "    if agent_states:\n",
    "        # Create a visualizer instance\n",
    "        visualizer = AgentVisualizer(processor.agent_behavior)\n",
    "\n",
    "        # Plot agent trajectories\n",
    "        visualizer.plot_agent_trajectories(variable_color=\"success_rate\")\n",
    "\n",
    "        # Create interactive visualization\n",
    "        animation = visualizer.create_interactive_visualization(max_frames=30)\n",
    "        animation\n",
    "\n",
    "    # 4. Calculate and visualize action entropy\n",
    "    entropy_data = processor.calculate_action_entropy()\n",
    "\n",
    "    if entropy_data is not None and not entropy_data.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        for agent_id in sorted(entropy_data[\"agent_id\"].unique()):\n",
    "            agent_data = entropy_data[entropy_data[\"agent_id\"] == agent_id]\n",
    "\n",
    "            plt.plot(\n",
    "                agent_data[\"window\"],\n",
    "                agent_data[\"entropy\"],\n",
    "                \"-o\",\n",
    "                markersize=4,\n",
    "                label=f\"Agent {agent_id}\",\n",
    "            )\n",
    "\n",
    "        plt.title(\"Action Entropy Over Time (Policy Convergence)\")\n",
    "        plt.xlabel(\"Time Window\")\n",
    "        plt.ylabel(\"Entropy (bits)\")\n",
    "        plt.axhline(y=1.0, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"Max Entropy\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863e261",
   "metadata": {},
   "source": [
    "## Visualizing SAT Specific Metrics\n",
    "\n",
    "This section focuses on SAT-specific visualizations like clause-variable graphs and conflict analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def generate_random_sat_instance(n_variables=20, n_clauses=80):\n",
    "    \"\"\"Generate a random SAT instance for visualization.\"\"\"\n",
    "    # Create random clauses\n",
    "    clauses = []\n",
    "    for _ in range(n_clauses):\n",
    "        # Each clause has 3 literals (3-SAT)\n",
    "        clause = []\n",
    "        for _ in range(3):\n",
    "            variable = random.randint(1, n_variables)\n",
    "            negated = random.choice([True, False])\n",
    "            literal = -variable if negated else variable\n",
    "            clause.append(literal)\n",
    "        clauses.append(clause)\n",
    "\n",
    "    return clauses\n",
    "\n",
    "\n",
    "def create_clause_variable_graph(clauses, variable_assignments=None):\n",
    "    \"\"\"Create a bipartite graph of clauses and variables.\"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add clause nodes\n",
    "    for i, clause in enumerate(clauses):\n",
    "        G.add_node(f\"c{i}\", type=\"clause\", clause=clause)\n",
    "\n",
    "    # Get the set of all variables\n",
    "    all_vars = set()\n",
    "    for clause in clauses:\n",
    "        for lit in clause:\n",
    "            all_vars.add(abs(lit))\n",
    "\n",
    "    # Add variable nodes\n",
    "    for var in all_vars:\n",
    "        # Get assignment if available\n",
    "        assignment = None\n",
    "        if variable_assignments is not None and var - 1 < len(variable_assignments):\n",
    "            assignment = variable_assignments[var - 1]\n",
    "\n",
    "        G.add_node(f\"v{var}\", type=\"variable\", var=var, assignment=assignment)\n",
    "\n",
    "    # Add edges between clauses and variables\n",
    "    for i, clause in enumerate(clauses):\n",
    "        for lit in clause:\n",
    "            G.add_edge(f\"c{i}\", f\"v{abs(lit)}\", negated=(lit < 0))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def visualize_clause_variable_graph(G, figsize=(12, 10)):\n",
    "    \"\"\"Visualize the clause-variable graph with satisfied/unsatisfied coloring.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Create position layout\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    # Collect nodes by type\n",
    "    clause_nodes = [n for n, d in G.nodes(data=True) if d[\"type\"] == \"clause\"]\n",
    "    var_nodes = [n for n, d in G.nodes(data=True) if d[\"type\"] == \"variable\"]\n",
    "\n",
    "    # Determine clause satisfaction\n",
    "    clause_colors = []\n",
    "    for node in clause_nodes:\n",
    "        clause = G.nodes[node][\"clause\"]\n",
    "        satisfied = False\n",
    "\n",
    "        for lit in clause:\n",
    "            var_node = f\"v{abs(lit)}\"\n",
    "            if G.nodes[var_node][\"assignment\"] is not None:\n",
    "                # Check if literal is satisfied\n",
    "                if (lit > 0 and G.nodes[var_node][\"assignment\"] == 1) or (\n",
    "                    lit < 0 and G.nodes[var_node][\"assignment\"] == 0\n",
    "                ):\n",
    "                    satisfied = True\n",
    "                    break\n",
    "\n",
    "        clause_colors.append(\"green\" if satisfied else \"red\")\n",
    "\n",
    "    # Determine variable colors based on assignment\n",
    "    var_colors = []\n",
    "    for node in var_nodes:\n",
    "        assignment = G.nodes[node][\"assignment\"]\n",
    "        if assignment is None:\n",
    "            var_colors.append(\"lightgray\")  # Unassigned\n",
    "        elif assignment == 1:\n",
    "            var_colors.append(\"blue\")  # True\n",
    "        else:\n",
    "            var_colors.append(\"orange\")  # False\n",
    "\n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(\n",
    "        G,\n",
    "        pos,\n",
    "        nodelist=clause_nodes,\n",
    "        node_color=clause_colors,\n",
    "        node_shape=\"s\",\n",
    "        node_size=500,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G,\n",
    "        pos,\n",
    "        nodelist=var_nodes,\n",
    "        node_color=var_colors,\n",
    "        node_shape=\"o\",\n",
    "        node_size=700,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # Draw edges with different colors for negated literals\n",
    "    regular_edges = [(u, v) for u, v, d in G.edges(data=True) if not d[\"negated\"]]\n",
    "    negated_edges = [(u, v) for u, v, d in G.edges(data=True) if d[\"negated\"]]\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=regular_edges, width=1.5)\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos, edgelist=negated_edges, width=1.5, style=\"dashed\", edge_color=\"red\"\n",
    "    )\n",
    "\n",
    "    # Add labels\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(\n",
    "        [\n",
    "            plt.Line2D(\n",
    "                [0], [0], marker=\"o\", color=\"w\", markerfacecolor=\"blue\", markersize=10\n",
    "            ),\n",
    "            plt.Line2D(\n",
    "                [0], [0], marker=\"o\", color=\"w\", markerfacecolor=\"orange\", markersize=10\n",
    "            ),\n",
    "            plt.Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=\"o\",\n",
    "                color=\"w\",\n",
    "                markerfacecolor=\"lightgray\",\n",
    "                markersize=10,\n",
    "            ),\n",
    "            plt.Line2D(\n",
    "                [0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"green\", markersize=10\n",
    "            ),\n",
    "            plt.Line2D(\n",
    "                [0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"red\", markersize=10\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            \"Variable = True\",\n",
    "            \"Variable = False\",\n",
    "            \"Variable = Unassigned\",\n",
    "            \"Clause Satisfied\",\n",
    "            \"Clause Unsatisfied\",\n",
    "        ],\n",
    "        loc=\"upper right\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Clause-Variable Graph\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage with the processor data\n",
    "if (\n",
    "    processor is not None\n",
    "    and hasattr(processor, \"variable_assignments\")\n",
    "    and processor.variable_assignments is not None\n",
    "):\n",
    "    # Get assignments for the last timestamp of the first episode\n",
    "    va_data = processor.variable_assignments\n",
    "\n",
    "    if not va_data.empty:\n",
    "        episode = va_data[\"episode\"].min()\n",
    "        episode_data = va_data[va_data[\"episode\"] == episode]\n",
    "        max_timestamp = episode_data[\"timestamp\"].max()\n",
    "\n",
    "        # Get final assignments for each variable\n",
    "        final_assignments = {}\n",
    "        for _, row in episode_data[\n",
    "            episode_data[\"timestamp\"] == max_timestamp\n",
    "        ].iterrows():\n",
    "            final_assignments[row[\"variable_idx\"]] = row[\"assignment\"]\n",
    "\n",
    "        # Create array of assignments\n",
    "        max_var = max(final_assignments.keys())\n",
    "        assignments = [final_assignments.get(i, -1) for i in range(max_var + 1)]\n",
    "\n",
    "        # Generate a random SAT instance\n",
    "        clauses = generate_random_sat_instance(\n",
    "            n_variables=len(assignments), n_clauses=100\n",
    "        )\n",
    "\n",
    "        # Create and visualize the graph\n",
    "        G = create_clause_variable_graph(clauses, assignments)\n",
    "        visualize_clause_variable_graph(G)\n",
    "    else:\n",
    "        print(\"No variable assignment data available\")\n",
    "else:\n",
    "    print(\"No processor data available for clause-variable graph visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satrlgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
